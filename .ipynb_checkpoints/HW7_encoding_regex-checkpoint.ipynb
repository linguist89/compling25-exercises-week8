{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e74142",
   "metadata": {},
   "source": [
    "# HW7: Counting and regular expressions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9044e2d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:18:08.839647Z",
     "iopub.status.busy": "2023-02-14T13:18:08.838873Z",
     "iopub.status.idle": "2023-02-14T13:18:12.323063Z",
     "shell.execute_reply": "2023-02-14T13:18:12.320818Z",
     "shell.execute_reply.started": "2023-02-14T13:18:08.839593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "# re module for working with regular expressions\n",
    "import re\n",
    "# For numerical work, nearly everyone uses numpy\n",
    "! pip install numpy\n",
    "from numpy import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e567d",
   "metadata": {},
   "source": [
    "## Part 1: Dictionaries and counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870631c",
   "metadata": {},
   "source": [
    "This notebook partly draws from materials put together by [Dirk Hovy](http://dirkhovy.com/). That's why there's a figure today! Dirk is a computational linguist at the University of Copenhagen. Much of his work tries to explore the intersection of social variables and NLP, working with large online corpora.\n",
    "\n",
    "### The structure of programs\n",
    "\n",
    "Most of programming, irrespective of the language you use, has four main elements:\n",
    "\n",
    "1. ***Assignment***: linking a name to a value. The names are called ***variables***. \n",
    "\n",
    "2. ***Loops***: sometimes we want to do the same thing repeatedly, either a fixed number of times, or\n",
    "until something happens. This is what loops are for. \n",
    "\n",
    "3. ***I/O (Input/Output)***: this refers to everything that has to do with getting information into and\n",
    "out of our programs, e.g. files (opening, closing, reading from or writing to them) or output on\n",
    "the screen.\n",
    "\n",
    "4. ***Control structures***: sometimes, we need to make decisions. I.e., if a variable has a certain \n",
    "value, do `X`, otherwise, do `Y`. Control structures are simple `if...then...else` constructs that evaluate\n",
    "the alternatives and make this decision. \n",
    "\n",
    "Today we'll put these together to do a useful elementary language processing task: getting counts of words in a document. The three main new things we need to learn today are: **reading from files**, **control structures**, and an important new data type the **dictionary** or just **dict**, which is a **mapping** data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31539608",
   "metadata": {},
   "source": [
    "### The dictionary (or \"dict\") data type\n",
    "\n",
    "Python uses the term \"dictionary\" or \"dict\" for a *mapping*: a collection of items of one type mapping to another type. A dictionary is written with curly braces. For example, here's a mapping, from web sites to my passwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5468c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:19:12.022499Z",
     "iopub.status.busy": "2023-02-14T13:19:12.021950Z",
     "iopub.status.idle": "2023-02-14T13:19:12.027307Z",
     "shell.execute_reply": "2023-02-14T13:19:12.026438Z",
     "shell.execute_reply.started": "2023-02-14T13:19:12.022462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "passwds = {'Amazon': 'curly', 'Google': 'furry', 'Apple': 'easy',\n",
    "           'Microsoft' : 'easy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be657c6e",
   "metadata": {},
   "source": [
    "No, not really! But it will do. You can access elements from a dict using the same square brackets notation after the dict/variable name, but now using a key which is the first half of the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90ce090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:19:29.592286Z",
     "iopub.status.busy": "2023-02-14T13:19:29.591705Z",
     "iopub.status.idle": "2023-02-14T13:19:29.598654Z",
     "shell.execute_reply": "2023-02-14T13:19:29.597549Z",
     "shell.execute_reply.started": "2023-02-14T13:19:29.592248Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Google password is: furry\n"
     ]
    }
   ],
   "source": [
    "print('My Google password is: ' + passwds['Google'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea055c",
   "metadata": {},
   "source": [
    "Trying to get a value for a key that doesn't exist is an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30eb2557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:19:35.227255Z",
     "iopub.status.busy": "2023-02-14T13:19:35.226701Z",
     "iopub.status.idle": "2023-02-14T13:19:35.396538Z",
     "shell.execute_reply": "2023-02-14T13:19:35.394761Z",
     "shell.execute_reply.started": "2023-02-14T13:19:35.227223Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LinkedIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpasswds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLinkedIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LinkedIN'"
     ]
    }
   ],
   "source": [
    "passwds['LinkedIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5747b",
   "metadata": {},
   "source": [
    "If we want to add a new item to our dictionary, we can simply assign a key a value:\n",
    "```\n",
    "<dictionary>[key] = <value>\n",
    "```\n",
    "\n",
    "Add the value `\"flotilla\"` as my `\"Facebook\"` pasword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0f7222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:19:48.015210Z",
     "iopub.status.busy": "2023-02-14T13:19:48.014363Z",
     "iopub.status.idle": "2023-02-14T13:19:48.025505Z",
     "shell.execute_reply": "2023-02-14T13:19:48.023913Z",
     "shell.execute_reply.started": "2023-02-14T13:19:48.015147Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amazon': 'curly',\n",
       " 'Google': 'furry',\n",
       " 'Apple': 'easy',\n",
       " 'Microsoft': 'easy',\n",
       " 'Facebook': 'flotilla'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the value \"flotilla\" as my \"Facebook\" pasword:\n",
    "passwds[\"Facebook\"] = \"flotilla\"\n",
    "passwds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73a900",
   "metadata": {},
   "source": [
    "In a dict, there can only be one value for a key, but several keys can have the same value. Oh, and while I said a key can have only one value, that value _can_ be a list, which lets you do general relations. A dictionary, unlike a list, isn't ordered. But you can very efficiently get the value for a key. You can also call 3 method `keys()`, `values()`, and `items()` which return list-like values that you can do a `for`-loop over to see all the keys, values, and mappings in the dict.  Try them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79346bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:20:21.811893Z",
     "iopub.status.busy": "2023-02-14T13:20:21.811065Z",
     "iopub.status.idle": "2023-02-14T13:20:21.819033Z",
     "shell.execute_reply": "2023-02-14T13:20:21.817894Z",
     "shell.execute_reply.started": "2023-02-14T13:20:21.811831Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon\n",
      "Google\n",
      "Apple\n",
      "Microsoft\n",
      "Facebook\n"
     ]
    }
   ],
   "source": [
    "for k in passwds.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c6f7e",
   "metadata": {},
   "source": [
    "Note that the keys didn't come out in the order that I wrote them down. You shouldn't rely on the order you wrote things down in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1bd2b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:20:31.183241Z",
     "iopub.status.busy": "2023-02-14T13:20:31.182422Z",
     "iopub.status.idle": "2023-02-14T13:20:31.190956Z",
     "shell.execute_reply": "2023-02-14T13:20:31.189704Z",
     "shell.execute_reply.started": "2023-02-14T13:20:31.183181Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curly\n",
      "furry\n",
      "easy\n",
      "easy\n",
      "flotilla\n"
     ]
    }
   ],
   "source": [
    "# Now print all the values\n",
    "for k in passwds.values():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8b3c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:20:40.813589Z",
     "iopub.status.busy": "2023-02-14T13:20:40.812546Z",
     "iopub.status.idle": "2023-02-14T13:20:40.821818Z",
     "shell.execute_reply": "2023-02-14T13:20:40.820706Z",
     "shell.execute_reply.started": "2023-02-14T13:20:40.813505Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon', 'curly')\n",
      "('Google', 'furry')\n",
      "('Apple', 'easy')\n",
      "('Microsoft', 'easy')\n",
      "('Facebook', 'flotilla')\n"
     ]
    }
   ],
   "source": [
    "# Now print all the items\n",
    "for k in passwds.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98af88",
   "metadata": {},
   "source": [
    "Note that the item is something we havent quite seen before – it's two strings wrapped in parentheses. It looks like the arguments to a function. This is different from a list and is called a ***tuple***. It's less important than lists, but we'll come back to them later today....\n",
    "\n",
    "You can check whether a key or value is in a map with the `in` and `not in` operators: `<key> in <dict>`. But that's often tedious to use, so you should also know the cleverer method on dicts `get(key, default)`, which lets you ask for a key, and return its value if it exists, or the default value otherwise. We'll be able to use it later to make our program neater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239a6ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:21:21.784565Z",
     "iopub.status.busy": "2023-02-14T13:21:21.783662Z",
     "iopub.status.idle": "2023-02-14T13:21:21.793485Z",
     "shell.execute_reply": "2023-02-14T13:21:21.792248Z",
     "shell.execute_reply.started": "2023-02-14T13:21:21.784483Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if I have an 'Amazon' password\n",
    "'Amazon' in passwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc481674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:21:26.982224Z",
     "iopub.status.busy": "2023-02-14T13:21:26.981382Z",
     "iopub.status.idle": "2023-02-14T13:21:26.992141Z",
     "shell.execute_reply": "2023-02-14T13:21:26.990778Z",
     "shell.execute_reply.started": "2023-02-14T13:21:26.982163Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flotilla'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either print my 'Facebook' password or 'None'\n",
    "passwds.get(\"Facebook\",0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c7d54",
   "metadata": {},
   "source": [
    "### Word Counts—Dictionaries and Control Structures\n",
    "\n",
    "Last week, we learned about variable assignment, loops, and printing to the screen.\n",
    "There are several useful object types that we have not yet covered, and we need to learn about the constructs that let us\n",
    "test conditions. We will see them in this program, as well as IO for reading from files.\n",
    "\n",
    "We want to know which words occur how often in a\n",
    "file. This is a common elementary text processing step in order to get some idea of your data and to get a sense of its overall topics. The output of such counting is precisely what people use to draw the very common visualization of [word clouds](http://www.wordle.net/). (Even though they're very common, many visualization people don't like them very much; just like pie charts.)\n",
    "\n",
    "Let’s first think about what we have and what we want. We have a ***file***, and we want the\n",
    "counts for the ***words*** in there. So there is a ***file***, ***sentences***, ***words***, and their ***counts***. We need to read the\n",
    "file, get the sentences; for each sentence, get the words, and somehow record their counts. In the end,\n",
    "we just print out the counts again. We can display this like in Figure 1.\n",
    "\n",
    "<img src=\"pics/diagram_word_counts.png\" width=\"500px\">\n",
    "<div align=\"center\">*Figure 1: Flow chart for our word count problem*</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a71054",
   "metadata": {},
   "source": [
    "Now let’s look at the program: it takes a file, reads it in, keeps a running count for each word, and\n",
    "prints those counts at the end. \n",
    "\n",
    "**Make sure to execute each code section as you progress (even the pre-written ones), so that the variables become available to the interpreter.** You won't see any direct output when executing the cell below, but we will need it further on.\n",
    "\n",
    "We first declare the name of the file as a variable, and then actually open the file. \n",
    "`open()` is the function that reads in the file. It takes just one argument: the name of the file we\n",
    "try to open. You can give it a second argument, `'w'` if you want to write to a file, rather than just read from it. Here, we only want to read, so we don't need to specify anything else.\n",
    "\n",
    "Python takes care of some pesky new line and encoding issues, so we won’t worry too much right now about special characters. Go ahead and read a file with runes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6eb3334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:23:58.424221Z",
     "iopub.status.busy": "2023-02-14T13:23:58.423410Z",
     "iopub.status.idle": "2023-02-14T13:23:58.431436Z",
     "shell.execute_reply": "2023-02-14T13:23:58.430033Z",
     "shell.execute_reply.started": "2023-02-14T13:23:58.424163Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = 'debate-clinton.txt'\n",
    "\n",
    "# open the file for reading\n",
    "text_file = open(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e49fc5",
   "metadata": {},
   "source": [
    "\n",
    "The result of running `open()` is not the text of the file. It is similar to a list (it's not exactly a list, but an ***iterator*** – that's also what `keys()` gave us above), and we call that list `text_file`, so we can use it later on. This give us a ***handle*** to read through the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4e25b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:24:16.902819Z",
     "iopub.status.busy": "2023-02-14T13:24:16.902025Z",
     "iopub.status.idle": "2023-02-14T13:24:16.908919Z",
     "shell.execute_reply": "2023-02-14T13:24:16.907498Z",
     "shell.execute_reply.started": "2023-02-14T13:24:16.902764Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_count = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441bcf4",
   "metadata": {},
   "source": [
    "After we have assigned the file hande, we assign the name `word_count` to a ***dictionary***. Here, our keys will be strings (the words), and the values we map them to are numbers (their respective\n",
    "frequencies). If we just use a pair of curly braces, as we\n",
    "did here, we get an empty dictionary. There are no entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8c1b9",
   "metadata": {},
   "source": [
    "After we have declared the dictionary, we start iterating through the file with a `for`-loop.\n",
    "Since `text_file` is an open file, this gives us a list of all the lines. We can\n",
    "thus iterate over them. For each line in the file, we want to do a number of things.\n",
    "That is why the next lines are all indented under the `for`-loop header line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c55256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:26:18.152255Z",
     "iopub.status.busy": "2023-02-14T13:26:18.151458Z",
     "iopub.status.idle": "2023-02-14T13:26:18.199300Z",
     "shell.execute_reply": "2023-02-14T13:26:18.197625Z",
     "shell.execute_reply.started": "2023-02-14T13:26:18.152200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# go through the open file line by line\n",
    "for line in text_file:\n",
    "    # get rid of the line break at the end\n",
    "    line = line.strip()\n",
    "    # split sentence along spaces\n",
    "    sentence = line.split()\n",
    "    # go through words\n",
    "    for word in sentence:\n",
    "        # check whether word is already in dictionary\n",
    "        if word in word_count:\n",
    "            # if yes: increment\n",
    "            word_count[word] = word_count[word] + 1\n",
    "        # if not, add an entry\n",
    "        else:\n",
    "            word_count[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ecc71",
   "metadata": {},
   "source": [
    "First, we get rid of the line break and any white space at the beginning or end of the line. We could write code to do all these things, but there is an easier (and shorter) way:\n",
    "we use the `strip()` command to remove all that whitespace from the line and assign it to \n",
    "the same name as before (`line`). (*Subtle point here about line break character!*) We made a new object – strings cannot be changed – but we assign it the same name. Whenever we use `line` from now on, it is the “cleaned-up” version of the line. (*Subtle points:* (1) Mutable and immutable objects; (2) If a method returns a new, changed object but doesn't change the original object – this is common and the only way to do things for immutable objects – then it is vital to assign the output of the method to something, or you will lose it. Commonly we assign it back to the same variable name if we conceptually think that we have *improved* the same thing.) \n",
    "\n",
    "We then use the `split()` command we have seen before next.\n",
    "Remember, it splits a sentence at the white space subsequences into a list, so if we had extra white spaces,\n",
    "it would create empty entries in our list. The list of strings resulting from `split()` is assigned to\n",
    "`sentence`, and we then iterate over that list. We have seen this before, so I will skip to the next\n",
    "interesting part here: control structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8c14f",
   "metadata": {},
   "source": [
    "After we have read the whole file, we close it with the `close()` command on the file variable. The dot tells us that it is a property of files. Note \n",
    "that this line is no longer indented under the `for`-loop, but at the same level. This means that it is only\n",
    "executed once we have completed all our iterations of the for-loop, in this case, after we have read all\n",
    "lines in the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2784f6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:28:11.124119Z",
     "iopub.status.busy": "2023-02-14T13:28:11.123337Z",
     "iopub.status.idle": "2023-02-14T13:28:11.130889Z",
     "shell.execute_reply": "2023-02-14T13:28:11.129553Z",
     "shell.execute_reply.started": "2023-02-14T13:28:11.124065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# close the file after reading\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd53ec",
   "metadata": {},
   "source": [
    "### Control Structures\n",
    "\n",
    "So far, we have simply executed one command after the next. We never had to make a decision or\n",
    "choose among options. Now we have to. If a word is already listed in our dictionary, we want to\n",
    "increase its count by one (we know how to do that). If the word is not in our dictionary, however, we\n",
    "have to make an entry. Otherwise, we would try to increment a count that does not even exist (you\n",
    "cannot look up something that is not in the dictionary).\n",
    "\n",
    "To make the decision what to do, we use the `if...then...else` structure or ***conditional***.\n",
    "The structure of the conditional is simple:\n",
    "```\n",
    "if <condition is true>:\n",
    "    <action1>\n",
    "else:\n",
    "    <action2>\n",
    "```\n",
    "\n",
    "Here `<condition>` is another type of variable, a so-called ***boolean***. They are named after the \n",
    "mathematician Boole, and have only two values: `True` and `False` (note the capital spelling!). In our\n",
    "case, the value comes from the outcome of the condition `word in word_count` to check whether\n",
    "the dictionary `word_count` contains the key word. **`in`** is one of Python’s reserved words. You can\n",
    "use it to check whether a variable is in a dictionary, a list, or other ***collections***.\n",
    "Sometimes, there are more than just two cases (something being true or false) that we would\n",
    "like to account for. In that case, we can check for more conditions:\n",
    "```\n",
    "if <condition1 is true>:\n",
    "    <action1>\n",
    "elif <condition2 is true>:\n",
    "    <action2>\n",
    "elif <condition3 is true>:\n",
    "    <action3>\n",
    "else:\n",
    "    <action4>\n",
    "```\n",
    "\n",
    "You can add as many `elif` cases as you want! We will see an example of this in the next section.\n",
    "\n",
    "So if the word we look at is indeed in our dictionary, we increment its count by one. \n",
    "This puts the current word in the dictionary and sets its counter to 1.\n",
    "\n",
    "Write your own control structure that checks whether `\"Amazon\"` is a key in `passwds`, and prints `\"Your password is <passwd>\"` if there is one and `\"You don't have an Amazon account!\"` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300140db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:36:03.052469Z",
     "iopub.status.busy": "2023-02-14T13:36:03.051676Z",
     "iopub.status.idle": "2023-02-14T13:36:03.060469Z",
     "shell.execute_reply": "2023-02-14T13:36:03.058970Z",
     "shell.execute_reply.started": "2023-02-14T13:36:03.052413Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your password is {'curly'}\n"
     ]
    }
   ],
   "source": [
    "if \"Amazon\" in passwds:\n",
    "    print(\"Your password is\", {passwds[\"Amazon\"]})\n",
    "else:\n",
    "    print(\"You dont have an Amazon account\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ad6e5",
   "metadata": {},
   "source": [
    "In our program, we finally want to print all the counts we have collected to the screen. We use another `for`-loop. This time, it iterates over a list of ***tuples***. Tuples are a lot like lists, with the big difference that they \n",
    "have a fixed size. They are less flexible than lists. In Python, we denote tuples by round brackets\n",
    "(instead of square ones as for lists). The function `items()` of a dictionary returns a list of \n",
    "tuples of each key and its respective value. We use that and assign them to `word` and `frequency`, respectively. We print each word and its frequency (provided it occurred more than once) separated by a space, (that is why there is a comma in the `print()` statement, see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7b7e4a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:36:59.433236Z",
     "iopub.status.busy": "2023-02-14T13:36:59.432448Z",
     "iopub.status.idle": "2023-02-14T13:36:59.454384Z",
     "shell.execute_reply": "2023-02-14T13:36:59.453406Z",
     "shell.execute_reply.started": "2023-02-14T13:36:59.433180Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How 4\n",
      "are 34\n",
      "you, 3\n",
      "Well, 26\n",
      "Lester, 3\n",
      "and 113\n",
      "to 220\n",
      "for 37\n",
      "us. 2\n",
      "The 6\n",
      "question 4\n",
      "in 90\n",
      "this 26\n",
      "is 51\n",
      "really 18\n",
      "what 37\n",
      "kind 10\n",
      "of 122\n",
      "country 8\n",
      "we 104\n",
      "want 18\n",
      "be 54\n",
      "future 3\n",
      "we'll 5\n",
      "build 3\n",
      "together. 2\n",
      "my 9\n",
      "second 3\n",
      "so 19\n",
      "I 133\n",
      "think 36\n",
      "about 33\n",
      "a 105\n",
      "First, 2\n",
      "have 81\n",
      "an 11\n",
      "economy 5\n",
      "that 108\n",
      "works 2\n",
      "everyone, 2\n",
      "not 34\n",
      "just 14\n",
      "those 7\n",
      "at 33\n",
      "the 228\n",
      "top. 3\n",
      "That 12\n",
      "means 4\n",
      "need 23\n",
      "new 9\n",
      "jobs, 5\n",
      "good 13\n",
      "with 35\n",
      "rising 3\n",
      "incomes. 2\n",
      "us 15\n",
      "invest 4\n",
      "you. 5\n",
      "your 23\n",
      "jobs 9\n",
      "small 3\n",
      "business, 3\n",
      "because 20\n",
      "most 4\n",
      "will 19\n",
      "come 5\n",
      "from 17\n",
      "business. 2\n",
      "We 24\n",
      "also 12\n",
      "make 16\n",
      "raising 2\n",
      "national 4\n",
      "minimum 2\n",
      "equal 2\n",
      "pay 7\n",
      "work. 4\n",
      "see 9\n",
      "more 21\n",
      "companies 2\n",
      "do 32\n",
      "If 3\n",
      "you 50\n",
      "help 4\n",
      "create 4\n",
      "should 15\n",
      "able 6\n",
      "share 3\n",
      "them, 2\n",
      "And 69\n",
      "support 7\n",
      "people 25\n",
      "who 19\n",
      "balance 2\n",
      "family 3\n",
      "I've 11\n",
      "heard 4\n",
      "many 10\n",
      "difficult 2\n",
      "face 3\n",
      "you're 6\n",
      "So 20\n",
      "let's 6\n",
      "paid 6\n",
      "sure 5\n",
      "care 2\n",
      "debt-free 2\n",
      "going 24\n",
      "We're 6\n",
      "it 43\n",
      "by 11\n",
      "having 5\n",
      "wealthy 5\n",
      "their 19\n",
      "fair 5\n",
      "close 2\n",
      "corporate 2\n",
      "on 25\n",
      "Donald 15\n",
      "Trump 2\n",
      "Donald, 3\n",
      "it's 13\n",
      "where 7\n",
      "important 7\n",
      "issues 2\n",
      "facing 4\n",
      "our 38\n",
      "country. 6\n",
      "You 13\n",
      "us, 2\n",
      "can 28\n",
      "responsibilities 3\n",
      "put 8\n",
      "into 9\n",
      "plans 3\n",
      "life 2\n",
      "hope 5\n",
      "vote 3\n",
      "trade 7\n",
      "issue. 2\n",
      "course, 2\n",
      "percent 2\n",
      "other 6\n",
      "percent. 4\n",
      "smart, 2\n",
      "deals. 2\n",
      "tax 15\n",
      "work 10\n",
      "financial 3\n",
      "plan 5\n",
      "has 29\n",
      "forth 2\n",
      "would 35\n",
      "all 11\n",
      "over 8\n",
      "again. 4\n",
      "In 4\n",
      "fact, 5\n",
      "biggest 4\n",
      "cuts 2\n",
      "top 2\n",
      "than 3\n",
      "we've 13\n",
      "ever 7\n",
      "call 2\n",
      "trumped-up 2\n",
      "that's 12\n",
      "be. 3\n",
      "how 9\n",
      "grow 2\n",
      "economy. 5\n",
      "different 6\n",
      "what's 2\n",
      "best 3\n",
      "economy, 3\n",
      "investments 2\n",
      "actually 7\n",
      "understand 3\n",
      "that. 11\n",
      "know, 13\n",
      "was 25\n",
      "very 12\n",
      "his 13\n",
      "benefit. 3\n",
      "He 10\n",
      "started 2\n",
      "business 10\n",
      "he 32\n",
      "people, 4\n",
      "better 5\n",
      "off 3\n",
      "everything 6\n",
      "out 13\n",
      "don't 10\n",
      "buy 4\n",
      "father 2\n",
      "worked 3\n",
      "hard. 2\n",
      "drapery 2\n",
      "fabrics 2\n",
      "long 3\n",
      "went 3\n",
      "down 3\n",
      "took 3\n",
      "kept 2\n",
      "believe 4\n",
      "middle 5\n",
      "class, 4\n",
      "education, 2\n",
      "That's 6\n",
      "were 9\n",
      "eight 2\n",
      "years 5\n",
      "ago. 2\n",
      "had 7\n",
      "worst 4\n",
      "since 3\n",
      "part 4\n",
      "policies 2\n",
      "taxes 3\n",
      "wealthy, 3\n",
      "failed 2\n",
      "Wall 2\n",
      "one 16\n",
      "said, 5\n",
      "back 7\n",
      "does 3\n",
      "then 5\n",
      "go 9\n",
      "some 11\n",
      "did 7\n",
      "million 9\n",
      "-- 29\n",
      "nine 2\n",
      "lost 2\n",
      "jobs. 2\n",
      "trillion 4\n",
      "out. 2\n",
      "Now, 2\n",
      "been 11\n",
      "we're 12\n",
      "now 5\n",
      "much 5\n",
      "but 13\n",
      "last 2\n",
      "thing 3\n",
      "first 4\n",
      "place. 2\n",
      "looked 5\n",
      "proposed 4\n",
      "Donald's 4\n",
      "proposed, 2\n",
      "they've 4\n",
      "said 8\n",
      "this, 2\n",
      "if 13\n",
      "plan, 2\n",
      "which 6\n",
      "up 9\n",
      "debt 4\n",
      "$5 3\n",
      "middle-class 2\n",
      "families 4\n",
      "lose 2\n",
      "3.5 2\n",
      "maybe 5\n",
      "another 2\n",
      "recession. 2\n",
      "They've 2\n",
      "intend 3\n",
      "get 15\n",
      "10 2\n",
      "making 4\n",
      "clean 2\n",
      "Some 2\n",
      "energy 2\n",
      "real. 2\n",
      "deal 6\n",
      "it, 5\n",
      "both 5\n",
      "home 4\n",
      "do. 11\n",
      "billion 2\n",
      "every 2\n",
      "home. 2\n",
      "lot 16\n",
      "tried 2\n",
      "do, 2\n",
      "am 3\n",
      "again, 4\n",
      "building 2\n",
      "made 5\n",
      "years, 2\n",
      "never 5\n",
      "got 14\n",
      "quite 2\n",
      "well, 5\n",
      "job 3\n",
      "... 15\n",
      "look 7\n",
      "facts. 2\n",
      "When 2\n",
      "number 4\n",
      "deals 2\n",
      "before 2\n",
      "them 10\n",
      "same 4\n",
      "Will 2\n",
      "they 19\n",
      "America? 2\n",
      "voted 2\n",
      "one, 2\n",
      "as 23\n",
      "hold 2\n",
      "these 5\n",
      "But 23\n",
      "only 6\n",
      "challenge 2\n",
      "I'm 7\n",
      "have, 2\n",
      "secretary 3\n",
      "state, 2\n",
      "increased 2\n",
      "American 9\n",
      "exports 2\n",
      "50 2\n",
      "know 10\n",
      "done 4\n",
      "opinion. 2\n",
      "against 3\n",
      "finally 2\n",
      "laid 2\n",
      "wrote 2\n",
      "live 2\n",
      "facts 2\n",
      "say 7\n",
      "when 16\n",
      "for, 2\n",
      "concluded 2\n",
      "even 6\n",
      "Look, 2\n",
      "there 13\n",
      "There 5\n",
      "country, 2\n",
      "leadership 2\n",
      "world. 2\n",
      "why 6\n",
      "add 3\n",
      "debt. 2\n",
      "it. 2\n",
      "It's 7\n",
      "called 6\n",
      "or 6\n",
      "near 3\n",
      "growth, 2\n",
      "can't 2\n",
      "taken 6\n",
      "are, 2\n",
      "take 5\n",
      "Because 2\n",
      "What 2\n",
      "time 2\n",
      "ISIS. 3\n",
      "No, 3\n",
      "not. 3\n",
      "fact 3\n",
      "feeling 2\n",
      "end 2\n",
      "not? 2\n",
      "Yeah, 2\n",
      "start 2\n",
      "Lester. 3\n",
      "We've 4\n",
      "kinds 5\n",
      "cause 2\n",
      "money 3\n",
      "happen 3\n",
      "way 2\n",
      "is... 2\n",
      "It 8\n",
      "worked. 2\n",
      "saying, 2\n",
      "college 2\n",
      "young 7\n",
      "rate. 2\n",
      "things 6\n",
      "you've 3\n",
      "seen 3\n",
      "switch 2\n",
      "here. 2\n",
      "40 3\n",
      "everyone 3\n",
      "president 2\n",
      "think, 2\n",
      "returns, 2\n",
      "clear 4\n",
      "no 6\n",
      "prohibition 2\n",
      "under 2\n",
      "release 2\n",
      "may 3\n",
      "couple 2\n",
      "he's 11\n",
      "says 3\n",
      "owes 2\n",
      "foreign 4\n",
      "federal 5\n",
      "turn 2\n",
      "state 3\n",
      "trying 5\n",
      "didn't 2\n",
      "any 6\n",
      "income 2\n",
      "zero 3\n",
      "troops, 2\n",
      "schools 2\n",
      "reasons 3\n",
      "something 5\n",
      "give 5\n",
      "They 5\n",
      "me 4\n",
      "deserve 3\n",
      "there's 2\n",
      "hiding. 2\n",
      "keep 3\n",
      "might 2\n",
      "is, 2\n",
      "Who 2\n",
      "that, 3\n",
      "provide 4\n",
      "them. 6\n",
      "using 2\n",
      "private 2\n",
      "claim 2\n",
      "United 5\n",
      "States 2\n",
      "talk 6\n",
      "campaign 2\n",
      "businesses 2\n",
      "And, 4\n",
      "met 3\n",
      "stiffed 2\n",
      "installers, 3\n",
      "like 3\n",
      "refused 2\n",
      "asked 2\n",
      "man 4\n",
      "needed 2\n",
      "someone 2\n",
      "certainly 2\n",
      "bankruptcy 2\n",
      "great 2\n",
      "try 4\n",
      "sometimes 4\n",
      "direct 2\n",
      "still 3\n",
      "determines 4\n",
      "too 9\n",
      "and, 2\n",
      "yes, 2\n",
      "they're 3\n",
      "criminal 5\n",
      "justice 5\n",
      "system. 4\n",
      "two 5\n",
      "time. 2\n",
      "restore 2\n",
      "communities 6\n",
      "police. 3\n",
      "police 8\n",
      "training, 2\n",
      "well 3\n",
      "prepared 3\n",
      "use 4\n",
      "respect 3\n",
      "Right 2\n",
      "now, 2\n",
      "neighborhoods. 2\n",
      "reform. 2\n",
      "begin 2\n",
      "problems 5\n",
      "challenges 2\n",
      "policing, 2\n",
      "together 2\n",
      "working 6\n",
      "mutual 2\n",
      "guns 2\n",
      "hands 3\n",
      "gun 5\n",
      "next 2\n",
      "seeing 2\n",
      "black 3\n",
      "opportunities 2\n",
      "There's 3\n",
      "proud 2\n",
      "supporting 2\n",
      "up. 2\n",
      "right 3\n",
      "ways 3\n",
      "doing 3\n",
      "ineffective. 2\n",
      "crime 3\n",
      "African-American 2\n",
      "men 2\n",
      "ended 2\n",
      "cannot 2\n",
      "law 3\n",
      "away 2\n",
      "Americans. 2\n",
      "this. 3\n",
      "weapons 2\n",
      "anyone 2\n",
      "being 3\n",
      "dangerous 2\n",
      "implicit 2\n",
      "bias 2\n",
      "unfortunately, 2\n",
      "hard 2\n",
      "health 2\n",
      "government 4\n",
      "could 3\n",
      "mayors, 2\n",
      "New 4\n",
      "York 2\n",
      "credit 2\n",
      "across 2\n",
      "want. 2\n",
      "communities, 4\n",
      "problem. 2\n",
      "else 2\n",
      "president. 3\n",
      "thing. 2\n",
      "cyber 5\n",
      "point 2\n",
      "information 5\n",
      "attacks 3\n",
      "coming 2\n",
      "doubt 2\n",
      "deeply 2\n",
      "Putin 2\n",
      "let 4\n",
      "hack 4\n",
      "files, 2\n",
      "information. 3\n",
      "whether 2\n",
      "after 4\n",
      "far 2\n",
      "defeat 3\n",
      "online. 2\n",
      "prevent 2\n",
      "ISIS 4\n",
      "military 2\n",
      "Iraq. 2\n",
      "Iraq 2\n",
      "weapons, 2\n",
      "efforts 2\n",
      "him 2\n",
      "agreement 2\n",
      "troops 2\n",
      "here 2\n",
      "intelligence 3\n",
      "enforcement 2\n",
      "Middle 2\n",
      "world, 2\n",
      "Muslim 3\n",
      "majority 2\n",
      "Muslims 2\n",
      "nations 2\n",
      "anywhere 2\n",
      "nuclear 8\n",
      "weapons. 2\n",
      "South 2\n",
      "matter 2\n",
      "word 3\n",
      "good. 2\n",
      "behalf 2\n",
      "Would 2\n",
      "secret 2\n",
      "around 3\n",
      "world 2\n",
      "women 2\n",
      "woman 2\n",
      "beauty 2\n",
      "\"Miss 2\n",
      "she 3\n"
     ]
    }
   ],
   "source": [
    "# take each pair of word and frequency in the dictionary\n",
    "for (word, frequency) in word_count.items():\n",
    "    if frequency > 1:\n",
    "        print(word, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65b022",
   "metadata": {},
   "source": [
    "Well, we've learned a fair bit here. We have learned how to read in a text file, how to use control structures, and we have\n",
    "seen the new object types dictionaries and tuples.\n",
    "You have now seen a lot of the basics of Python! While there are a lot of other things that you *can* learn – and, gosh, I'm going to attempt to teach quite a few of them — you can actually write quite a bit of basic text processing using just these elements. Many of the things that we'll learn later provide faster, more powerful, more convenient ways to do things that you _could_ do with just these elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687655d",
   "metadata": {},
   "source": [
    "### Doing more with word counts from the Clinton-Trump debate\n",
    "\n",
    "Try to do all of these things, and end up with a decent program at the end that does all this stuff.\n",
    "\n",
    "The above program got word counts from the file `'debate-clinton.txt'`. It was hardcoded to do so. But we also want word counts from `'debate-trump.txt'`. So, what we want is a function that can count words in _any_ file.  We might structure our program as two functions:\n",
    "\n",
    "1. A function that takes a string filename and returns a dict from words to their counts in the file.\n",
    "\n",
    "2. A function that takes a dict of word counts and prints the word counts\n",
    "\n",
    "You are welcome to copy and paste any code from above to get this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef95f848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T14:09:47.756282Z",
     "iopub.status.busy": "2023-02-14T14:09:47.755475Z",
     "iopub.status.idle": "2023-02-14T14:09:47.767032Z",
     "shell.execute_reply": "2023-02-14T14:09:47.765870Z",
     "shell.execute_reply.started": "2023-02-14T14:09:47.756227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for collecting word counts from a file\n",
    "# Don't forget to close the file after you have read it in!\n",
    "def word_count(text_path):\n",
    "    text = open(text_path)\n",
    "    word_count = {}\n",
    "    stop_words = ['the', 'a', 'an', 'that', 'and', 'to', 'of']\n",
    "    # go through the open file line by line\n",
    "    for line in text:\n",
    "        # get rid of the line break at the end\n",
    "        line = line.strip()\n",
    "        # split sentence along spaces\n",
    "        sentence = line.split()\n",
    "        # go through words\n",
    "        for word in sentence:\n",
    "            if word in stop_words:\n",
    "                pass\n",
    "            # check whether word is already in dictionary\n",
    "            elif word in word_count:\n",
    "                # if yes: increment\n",
    "                word_count[word] = word_count[word] + 1\n",
    "            # if not, add an entry\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "    text.close()\n",
    "    min_freq = int(input())\n",
    "    for (word, frequency) in word_count.items():\n",
    "        if frequency > min_freq:\n",
    "            print(word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d0b4765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:51:22.390857Z",
     "iopub.status.busy": "2023-02-14T13:51:22.390177Z",
     "iopub.status.idle": "2023-02-14T13:51:22.399097Z",
     "shell.execute_reply": "2023-02-14T13:51:22.397611Z",
     "shell.execute_reply.started": "2023-02-14T13:51:22.390799Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for printing word counts from a dict\n",
    "# take each pair of word and frequency in the dictionary\n",
    "def print_count(word_count):\n",
    "    for (word, frequency) in word_count.items():\n",
    "        if frequency > 1:\n",
    "            print(word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9231b6f5-b9d1-4957-a731-69a9b84ff43c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:51:22.735899Z",
     "iopub.status.busy": "2023-02-14T13:51:22.735110Z",
     "iopub.status.idle": "2023-02-14T13:51:22.743114Z",
     "shell.execute_reply": "2023-02-14T13:51:22.741455Z",
     "shell.execute_reply.started": "2023-02-14T13:51:22.735840Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = [\"debate-trump.txt\", \"debate-clinton.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c0fcfa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T14:09:50.614980Z",
     "iopub.status.busy": "2023-02-14T14:09:50.614186Z",
     "iopub.status.idle": "2023-02-14T14:09:55.096686Z",
     "shell.execute_reply": "2023-02-14T14:09:55.095752Z",
     "shell.execute_reply.started": "2023-02-14T14:09:50.614923Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Printing word count for debate-trump.txt \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you, 6\n",
      "Lester. 4\n",
      "Our 7\n",
      "jobs 7\n",
      "are 54\n",
      "the 265\n",
      "country. 13\n",
      "They're 11\n",
      "going 45\n",
      "to 250\n",
      "many 26\n",
      "other 19\n",
      "countries. 5\n",
      "You 38\n",
      "look 31\n",
      "at 44\n",
      "what 38\n",
      "China 4\n",
      "is 70\n",
      "doing 23\n",
      "our 53\n",
      "country 26\n",
      "in 97\n",
      "terms 5\n",
      "of 162\n",
      "their 19\n",
      "and 159\n",
      "there's 7\n",
      "nobody 7\n",
      "them. 9\n",
      "And 119\n",
      "we 82\n",
      "have 141\n",
      "a 166\n",
      "very 62\n",
      "good 13\n",
      "Because 7\n",
      "they're 28\n",
      "as 24\n",
      "countries 6\n",
      "thing. 5\n",
      "So 18\n",
      "we're 19\n",
      "losing 6\n",
      "jobs, 5\n",
      "so 26\n",
      "When 14\n",
      "you 148\n",
      "what's 6\n",
      "who 7\n",
      "said 20\n",
      "it's 45\n",
      "some 15\n",
      "biggest 5\n",
      "anywhere 4\n",
      "world, 7\n",
      "United 4\n",
      "he 8\n",
      "said, 14\n",
      "not 45\n",
      "leaving. 6\n",
      "see 9\n",
      "that, 9\n",
      "leaving 7\n",
      "all 30\n",
      "can't 18\n",
      "it 61\n",
      "As 5\n",
      "far 7\n",
      "care 5\n",
      "I 229\n",
      "think 36\n",
      "Hillary 6\n",
      "agree 9\n",
      "on 43\n",
      "that. 19\n",
      "We 39\n",
      "probably 5\n",
      "little 6\n",
      "but 22\n",
      "we'll 4\n",
      "be 51\n",
      "talking 8\n",
      "about 34\n",
      "that 119\n",
      "But 56\n",
      "stop 8\n",
      "from 22\n",
      "being 4\n",
      "us. 4\n",
      "companies 14\n",
      "with 50\n",
      "it, 10\n",
      "people. 6\n",
      "All 8\n",
      "do 44\n",
      "take 13\n",
      "They 15\n",
      "left 4\n",
      "-- 102\n",
      "hundreds 4\n",
      "this. 6\n",
      "cannot 5\n",
      "let 5\n",
      "my 14\n",
      "I'll 11\n",
      "taxes 6\n",
      "for 40\n",
      "big 6\n",
      "That's 6\n",
      "job 6\n",
      "like 22\n",
      "haven't 7\n",
      "seen 4\n",
      "since 5\n",
      "It's 27\n",
      "thing 13\n",
      "will 28\n",
      "New 7\n",
      "very, 9\n",
      "much 12\n",
      "it. 33\n",
      "trade 9\n",
      "these 16\n",
      "jobs. 6\n",
      "Well, 16\n",
      "one 21\n",
      "before 6\n",
      "me 21\n",
      "into 13\n",
      "that's 23\n",
      "billions 5\n",
      "greatest 7\n",
      "say 20\n",
      "only 6\n",
      "because 51\n",
      "thinking 4\n",
      "don't 30\n",
      "know 13\n",
      "when 28\n",
      "over 14\n",
      "ever 13\n",
      "us 8\n",
      "deals. 4\n",
      "And, 4\n",
      "Lester, 7\n",
      "taking 8\n",
      "things 14\n",
      "do. 6\n",
      "Let 4\n",
      "give 7\n",
      "We're 6\n",
      "different 5\n",
      "they 54\n",
      "no 14\n",
      "been 38\n",
      "long 7\n",
      "time, 7\n",
      "years, 9\n",
      "politicians 7\n",
      "done 7\n",
      "Now, 8\n",
      "Secretary 23\n",
      "Clinton 15\n",
      "OK? 4\n",
      "want 22\n",
      "me. 7\n",
      "she 24\n",
      "this, 7\n",
      "was 65\n",
      "really 18\n",
      "She's 6\n",
      "this 27\n",
      "30 6\n",
      "years. 7\n",
      "why 6\n",
      "made 5\n",
      "The 21\n",
      "Just 5\n",
      "tax 10\n",
      "just 34\n",
      "should 25\n",
      "right 8\n",
      "now, 5\n",
      "fact 4\n",
      "we've 5\n",
      "look, 5\n",
      "$20 6\n",
      "trillion. 4\n",
      "any 4\n",
      "first 8\n",
      "could 15\n",
      "mean, 8\n",
      "there 5\n",
      "thousands 6\n",
      "than 11\n",
      "say, 7\n",
      "go 19\n",
      "or 17\n",
      "country, 9\n",
      "lot 13\n",
      "if 18\n",
      "you're 15\n",
      "make 6\n",
      "your 17\n",
      "bring 15\n",
      "them 22\n",
      "wrong. 5\n",
      "in, 4\n",
      "never 8\n",
      "cases, 4\n",
      "I'm 30\n",
      "saying 6\n",
      "is, 5\n",
      "can 8\n",
      "called 5\n",
      "by 25\n",
      "way. 4\n",
      "did 18\n",
      "She 5\n",
      "talks 5\n",
      "That 14\n",
      "disaster. 4\n",
      "money 10\n",
      "great 13\n",
      "people 25\n",
      "out 20\n",
      "paying 6\n",
      "trillion 7\n",
      "Obama 6\n",
      "time 4\n",
      "come 7\n",
      "he's 4\n",
      "almost 9\n",
      "tell 15\n",
      "better 9\n",
      "new 11\n",
      "where 13\n",
      "I'd 5\n",
      "ask 4\n",
      "Why 4\n",
      "you've 7\n",
      "now 6\n",
      "back 11\n",
      "He 6\n",
      "which 12\n",
      "single 5\n",
      "worst 7\n",
      "deal 7\n",
      "years 6\n",
      "down 7\n",
      "maybe 5\n",
      "certainly 5\n",
      "approve 5\n",
      "were 21\n",
      "totally 5\n",
      "how 8\n",
      "bad 12\n",
      "would 20\n",
      "then 6\n",
      "against 12\n",
      "President 6\n",
      "business 5\n",
      "out. 6\n",
      "regulations 4\n",
      "way, 5\n",
      "proud 4\n",
      "It 17\n",
      "tremendous 10\n",
      "I've 10\n",
      "over. 4\n",
      "even 11\n",
      "raise 4\n",
      "her 14\n",
      "website. 4\n",
      "ISIS. 4\n",
      "ISIS 6\n",
      "No, 7\n",
      "major 5\n",
      "getting 5\n",
      "interest 4\n",
      "put 4\n",
      "believe 13\n",
      "lots 5\n",
      "everybody 6\n",
      "brought 5\n",
      "get 26\n",
      "inner 6\n",
      "Clinton. 4\n",
      "didn't 9\n",
      "read 4\n",
      "doesn't 10\n",
      "an 12\n",
      "Fed 4\n",
      "political 6\n",
      "things. 5\n",
      "day 4\n",
      "his 4\n",
      "more 14\n",
      "under 4\n",
      "learn 4\n",
      "Look, 5\n",
      "way 11\n",
      "has 13\n",
      "taken 10\n",
      "of. 5\n",
      "them, 5\n",
      "up 11\n",
      "me, 8\n",
      "you. 7\n",
      "money. 4\n",
      "help 7\n",
      "These 4\n",
      "company. 4\n",
      "had 11\n",
      "somebody 5\n",
      "know, 12\n",
      "world 4\n",
      "land 5\n",
      "happened. 4\n",
      "started. 4\n",
      "Middle 6\n",
      "East, 4\n",
      "problem. 4\n",
      "Wrong. 6\n",
      "Some 4\n",
      "four 4\n",
      "used 5\n",
      "there. 4\n",
      "all, 4\n",
      "advantage 4\n",
      "doing. 5\n",
      "supposed 4\n",
      "able 7\n",
      "law 7\n",
      "order. 5\n",
      "need 12\n",
      "throughout 4\n",
      "whether 6\n",
      "got 13\n",
      "In 4\n",
      "this? 4\n",
      "last 7\n",
      "Barack 4\n",
      "Chicago 4\n",
      "away 4\n",
      "shouldn't 5\n",
      "African-American 5\n",
      "went 4\n",
      "her. 4\n",
      "community, 4\n",
      "community 5\n",
      "terrible 4\n",
      "relationships 4\n",
      "watch 4\n",
      "say. 4\n",
      "York 4\n",
      "respond. 4\n",
      "campaign 7\n",
      "sent 4\n",
      "find 4\n",
      "birth 4\n",
      "certificate. 4\n",
      "him 7\n",
      "also 6\n",
      "endorsed 6\n",
      "10 4\n",
      "Russia, 6\n",
      "another 4\n",
      "cyber 4\n",
      "something 4\n",
      "oil 6\n",
      "Iran 5\n",
      "asked 4\n",
      "NATO. 4\n",
      "war 6\n",
      "Sean 8\n",
      "war. 5\n",
      "nuclear 6\n",
      "defend 7\n",
      "she's 5\n",
      "North 5\n",
      "Korea. 4\n",
      "stamina. 5\n",
      "\n",
      " Printing word count for debate-clinton.txt \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How 4\n",
      "are 34\n",
      "Well, 26\n",
      "and 113\n",
      "to 220\n",
      "for 37\n",
      "The 6\n",
      "question 4\n",
      "in 90\n",
      "this 26\n",
      "is 51\n",
      "really 18\n",
      "what 37\n",
      "kind 10\n",
      "of 122\n",
      "country 8\n",
      "we 104\n",
      "want 18\n",
      "be 54\n",
      "we'll 5\n",
      "my 9\n",
      "so 19\n",
      "I 133\n",
      "think 36\n",
      "about 33\n",
      "a 105\n",
      "have 81\n",
      "an 11\n",
      "economy 5\n",
      "that 108\n",
      "not 34\n",
      "just 14\n",
      "those 7\n",
      "at 33\n",
      "the 228\n",
      "That 12\n",
      "means 4\n",
      "need 23\n",
      "new 9\n",
      "jobs, 5\n",
      "good 13\n",
      "with 35\n",
      "us 15\n",
      "invest 4\n",
      "you. 5\n",
      "your 23\n",
      "jobs 9\n",
      "because 20\n",
      "most 4\n",
      "will 19\n",
      "come 5\n",
      "from 17\n",
      "We 24\n",
      "also 12\n",
      "make 16\n",
      "national 4\n",
      "pay 7\n",
      "work. 4\n",
      "see 9\n",
      "more 21\n",
      "do 32\n",
      "you 50\n",
      "help 4\n",
      "create 4\n",
      "should 15\n",
      "able 6\n",
      "And 69\n",
      "support 7\n",
      "people 25\n",
      "who 19\n",
      "I've 11\n",
      "heard 4\n",
      "many 10\n",
      "you're 6\n",
      "So 20\n",
      "let's 6\n",
      "paid 6\n",
      "sure 5\n",
      "going 24\n",
      "We're 6\n",
      "it 43\n",
      "by 11\n",
      "having 5\n",
      "wealthy 5\n",
      "their 19\n",
      "fair 5\n",
      "on 25\n",
      "Donald 15\n",
      "it's 13\n",
      "where 7\n",
      "important 7\n",
      "facing 4\n",
      "our 38\n",
      "country. 6\n",
      "You 13\n",
      "can 28\n",
      "put 8\n",
      "into 9\n",
      "hope 5\n",
      "trade 7\n",
      "other 6\n",
      "percent. 4\n",
      "tax 15\n",
      "work 10\n",
      "plan 5\n",
      "has 29\n",
      "would 35\n",
      "all 11\n",
      "over 8\n",
      "again. 4\n",
      "In 4\n",
      "fact, 5\n",
      "biggest 4\n",
      "we've 13\n",
      "ever 7\n",
      "that's 12\n",
      "how 9\n",
      "economy. 5\n",
      "different 6\n",
      "actually 7\n",
      "that. 11\n",
      "know, 13\n",
      "was 25\n",
      "very 12\n",
      "his 13\n",
      "He 10\n",
      "business 10\n",
      "he 32\n",
      "people, 4\n",
      "better 5\n",
      "everything 6\n",
      "out 13\n",
      "don't 10\n",
      "buy 4\n",
      "believe 4\n",
      "middle 5\n",
      "class, 4\n",
      "That's 6\n",
      "were 9\n",
      "years 5\n",
      "had 7\n",
      "worst 4\n",
      "part 4\n",
      "one 16\n",
      "said, 5\n",
      "back 7\n",
      "then 5\n",
      "go 9\n",
      "some 11\n",
      "did 7\n",
      "million 9\n",
      "-- 29\n",
      "trillion 4\n",
      "been 11\n",
      "we're 12\n",
      "now 5\n",
      "much 5\n",
      "but 13\n",
      "first 4\n",
      "looked 5\n",
      "proposed 4\n",
      "Donald's 4\n",
      "they've 4\n",
      "said 8\n",
      "if 13\n",
      "which 6\n",
      "up 9\n",
      "debt 4\n",
      "families 4\n",
      "maybe 5\n",
      "get 15\n",
      "making 4\n",
      "deal 6\n",
      "it, 5\n",
      "both 5\n",
      "home 4\n",
      "do. 11\n",
      "lot 16\n",
      "again, 4\n",
      "made 5\n",
      "never 5\n",
      "got 14\n",
      "well, 5\n",
      "... 15\n",
      "look 7\n",
      "number 4\n",
      "them 10\n",
      "same 4\n",
      "they 19\n",
      "as 23\n",
      "these 5\n",
      "But 23\n",
      "only 6\n",
      "I'm 7\n",
      "American 9\n",
      "know 10\n",
      "done 4\n",
      "say 7\n",
      "when 16\n",
      "even 6\n",
      "there 13\n",
      "There 5\n",
      "why 6\n",
      "It's 7\n",
      "called 6\n",
      "or 6\n",
      "taken 6\n",
      "take 5\n",
      "We've 4\n",
      "kinds 5\n",
      "It 8\n",
      "young 7\n",
      "things 6\n",
      "clear 4\n",
      "no 6\n",
      "he's 11\n",
      "foreign 4\n",
      "federal 5\n",
      "trying 5\n",
      "any 6\n",
      "something 5\n",
      "give 5\n",
      "They 5\n",
      "me 4\n",
      "provide 4\n",
      "them. 6\n",
      "United 5\n",
      "talk 6\n",
      "And, 4\n",
      "man 4\n",
      "try 4\n",
      "sometimes 4\n",
      "determines 4\n",
      "too 9\n",
      "criminal 5\n",
      "justice 5\n",
      "system. 4\n",
      "two 5\n",
      "communities 6\n",
      "police 8\n",
      "use 4\n",
      "problems 5\n",
      "working 6\n",
      "gun 5\n",
      "government 4\n",
      "New 4\n",
      "communities, 4\n",
      "cyber 5\n",
      "information 5\n",
      "let 4\n",
      "hack 4\n",
      "after 4\n",
      "ISIS 4\n",
      "nuclear 8\n"
     ]
    }
   ],
   "source": [
    "# Top-level code that calls the above functions for each of the files\n",
    "# 'debate-clinton.txt' and 'debate-trump.txt'.\n",
    "# You probably also want to print out a blank line separator dividing the files and saying which you are printing.\n",
    "for text_path in files:\n",
    "    print(f\"\\n Printing word count for {text_path} \\n\")\n",
    "    word_count(text_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb2750",
   "metadata": {},
   "source": [
    "Let's now try to make that program a bit better! You can just edit it above and leave the final program.\n",
    "\n",
    "1. Although it was useful to learn about `if` control structures – and we will use them a lot – you don't actually need to use one here. Do you instead remember about the `get(<key>, <default>)` method on a dict that we saw earlier? Try using it. *(Warning: this can be challenging so it is fine to skip it at first and come back later)*.\n",
    "\n",
    "2. The above code is hardcoded to print words that occur 2 or more times. This makes the list shorter by leaving out words that occur only once (the \"hapax legomena\" of the list — there are always a lot of these, often about 40% of the word types). But it's still a long list. We might want to only print words that occur 3 or more times, say. Make the minimum number of times for a word to occur to print it another parameter of the second function, and have the top-level code call it with the value 3.\n",
    "\n",
    "3. At the other extreme, it might not be very interesting knowing how often the candidates say \"the\" or \"to\". Such function words often don't seem to carry much content. (Though, of course, be aware of the work of people such as [James Pennebaker](http://www.secretlifeofpronouns.com/), who emphasizes how much social meaning can be conveyed by function words. Lists of common function words that you are not going to count are conventionally called **stop words** in computational work. Modify the first program to also accept a list of stop words which you don't put in the hash. Modify the top-level code so that it doesn't count `['the', 'a', 'an', 'that', 'and', 'to', 'of']`\n",
    "\n",
    "4. We're starting to suffer badly from simply tokenizing by dividing on whitespace. We could do a little better by simply \"whiting out\" the commonest punctuation marks that glom on to words. Before splitting on white space, we could change the string to delete letters like: `'.', ',', '\"'`. Remember the `replace()` method on `str` that we saw last time. Look at your output, you may well want to delete a few more. Doing this will do a little textual damage; e.g., `30,000` will become `30000`, but it won't be too bad. You may want to not delete `'`, though, so that you don't damage words like `isn't`.\n",
    "\n",
    "5. It might also be useful to lowercase all tokens, so that words don't become different just because they are at the start of a sentence. Of course, you'll then just have to be smart enough to recognize that `irs` means the `IRS`.\n",
    "\n",
    "6. It would be good to also add up how many non-stop words were spoken by each candidate. Who spoke the most?\n",
    "\n",
    "7. To normalize for frequency, it would be useful to also work out the percent of times the word each candidate says is a certain word. So, in the second function, also print the percent as well as the raw count.\n",
    "\n",
    "8. Find at least one interesting difference in word use between the two candidates, and put it in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8bfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3306f34",
   "metadata": {},
   "source": [
    "### Bonus: Getting word counts from the Google Books data\n",
    "\n",
    "The raw data files for the Google Books collection are available for \n",
    "download. The files are huge, so I created a tiny sample in the file `googlebooks-eng-all-1gram-20120701-a-sample`.\n",
    "\n",
    "The format of this file is as follows (whitespace inserted for \n",
    "readability):\n",
    "\n",
    "```\n",
    "word TAB year TAB match_count TAB volume_count NEWLINE\n",
    "```\n",
    "\n",
    "The TAB character is \"\\t\", which you can treat like any other (for\n",
    "example, you can split a string on \"\\t\"). The `match_count` is how many times the word occurred and the `volume_count` is a smaller number for how many _different_ books it occurred in. We will use the `match_count`. Note that the words have also been disambiguated by part of speech where ambiguous. We'll get to that later.\n",
    "\n",
    "Your first task: complete googlebooks_counts_by_year so that it processes\n",
    "my sample file and returns a 2d dictionary (a top-level dictionary whose values are each a dictionary!) with this structure:\n",
    "\n",
    "{\n",
    "  word1: {year1: count, year2: count ...},\n",
    "  word2: {year1: count, year2: count ...},\n",
    "  ...\n",
    "}\n",
    "\n",
    "where the contents of the year dicts is determined by the file.\n",
    "(That is, different words will have different years and counts\n",
    "associated with them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da993a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlebooks_counts_by_year(filename):\n",
    "    \"\"\"Maps a Google books 1-grams file to a 2d dictionary\n",
    "    giving each word's counts by year.\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85223e2f",
   "metadata": {},
   "source": [
    "Second task: Complete the function googlebooks_year_collapse so that it takes as input the output of googlebooks_counts_by_year and collapses\n",
    "it down so that each word is associated with its single tokencount\n",
    "for the full, obtained by summing up all of the counts for the\n",
    "years associated with that word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ada65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlebooks_year_collapse(d):\n",
    "    \"\"\"Convert the output of googlebooks_counts_by_year to \n",
    "    a simpler dict mapping words to counts.\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46e98e",
   "metadata": {},
   "source": [
    "Write something at the top-level to call this code on the file `googlebooks-eng-all-1gram-20120701-a-sample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28c135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbd799be",
   "metadata": {},
   "source": [
    "## Part 2: Regular Expressions in Python\n",
    "\n",
    "Regular expressions – regex – are super useful when processing text in Python! However, there are so many different patterns and ways to use the re module that it is impossible to learn by heart. So instead, this part of the HW is for you to play around and get comfortable with using regex. Also, head to [regex101.com](http://www.regex101.com/) for a nice place to test out your regex patterns before running them here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657b91cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:45.871434Z",
     "iopub.status.busy": "2023-02-14T11:40:45.870765Z",
     "iopub.status.idle": "2023-02-14T11:40:45.881042Z",
     "shell.execute_reply": "2023-02-14T11:40:45.880120Z",
     "shell.execute_reply.started": "2023-02-14T11:40:45.871381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[a-z]+', re.UNICODE)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile('[a-z]+')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2718541d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:48.688708Z",
     "iopub.status.busy": "2023-02-14T11:40:48.688061Z",
     "iopub.status.idle": "2023-02-14T11:40:48.698213Z",
     "shell.execute_reply": "2023-02-14T11:40:48.697215Z",
     "shell.execute_reply.started": "2023-02-14T11:40:48.688657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='tempo'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a few different things instead of 'tempo' - can you find the things that don't match?\n",
    "m = p.match('tempo')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abfd5481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:50.512424Z",
     "iopub.status.busy": "2023-02-14T11:40:50.511195Z",
     "iopub.status.idle": "2023-02-14T11:40:50.521389Z",
     "shell.execute_reply": "2023-02-14T11:40:50.519727Z",
     "shell.execute_reply.started": "2023-02-14T11:40:50.512369Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tempo'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0be1c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:52.050880Z",
     "iopub.status.busy": "2023-02-14T11:40:52.050265Z",
     "iopub.status.idle": "2023-02-14T11:40:52.060865Z",
     "shell.execute_reply": "2023-02-14T11:40:52.059289Z",
     "shell.execute_reply.started": "2023-02-14T11:40:52.050828Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.start(), m.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa1b7077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:53.734961Z",
     "iopub.status.busy": "2023-02-14T11:40:53.734135Z",
     "iopub.status.idle": "2023-02-14T11:40:53.743865Z",
     "shell.execute_reply": "2023-02-14T11:40:53.741999Z",
     "shell.execute_reply.started": "2023-02-14T11:40:53.734905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(p.match('::: message'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42413e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:55.141064Z",
     "iopub.status.busy": "2023-02-14T11:40:55.140311Z",
     "iopub.status.idle": "2023-02-14T11:40:55.149197Z",
     "shell.execute_reply": "2023-02-14T11:40:55.147897Z",
     "shell.execute_reply.started": "2023-02-14T11:40:55.141012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 11), match='message'>\n"
     ]
    }
   ],
   "source": [
    "m = p.search('::: message'); print(m)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f408dc4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:57.419257Z",
     "iopub.status.busy": "2023-02-14T11:40:57.418578Z",
     "iopub.status.idle": "2023-02-14T11:40:57.427510Z",
     "shell.execute_reply": "2023-02-14T11:40:57.426267Z",
     "shell.execute_reply.started": "2023-02-14T11:40:57.419201Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found:  a\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('[a-z]+')\n",
    "m = p.search( '2942a9vv4dxaq42' )\n",
    "if m:\n",
    "    print('Match found: ', m.group())\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe6c4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:40:58.966812Z",
     "iopub.status.busy": "2023-02-14T11:40:58.966190Z",
     "iopub.status.idle": "2023-02-14T11:40:58.976035Z",
     "shell.execute_reply": "2023-02-14T11:40:58.974878Z",
     "shell.execute_reply.started": "2023-02-14T11:40:58.966759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'vv', 'dxaq']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.findall('2942a9vv4dxaq42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "194b1987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:00.519577Z",
     "iopub.status.busy": "2023-02-14T11:41:00.518923Z",
     "iopub.status.idle": "2023-02-14T11:41:00.529372Z",
     "shell.execute_reply": "2023-02-14T11:41:00.528186Z",
     "shell.execute_reply.started": "2023-02-14T11:41:00.519521Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='From '>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shortcut pattern and matcher in one!\n",
    "re.match(r'From\\s+', 'From amk Thu May 14 19:12:10 1998')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cde418",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a682003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:02.656110Z",
     "iopub.status.busy": "2023-02-14T11:41:02.655444Z",
     "iopub.status.idle": "2023-02-14T11:41:02.666367Z",
     "shell.execute_reply": "2023-02-14T11:41:02.665242Z",
     "shell.execute_reply.started": "2023-02-14T11:41:02.656056Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile('(a(b)c)d')\n",
    "m = p.match('abcd')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ef1637c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:04.376862Z",
     "iopub.status.busy": "2023-02-14T11:41:04.376237Z",
     "iopub.status.idle": "2023-02-14T11:41:04.385932Z",
     "shell.execute_reply": "2023-02-14T11:41:04.384965Z",
     "shell.execute_reply.started": "2023-02-14T11:41:04.376808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75425f2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:05.823603Z",
     "iopub.status.busy": "2023-02-14T11:41:05.823002Z",
     "iopub.status.idle": "2023-02-14T11:41:05.832669Z",
     "shell.execute_reply": "2023-02-14T11:41:05.831504Z",
     "shell.execute_reply.started": "2023-02-14T11:41:05.823552Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e183a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:07.931084Z",
     "iopub.status.busy": "2023-02-14T11:41:07.930450Z",
     "iopub.status.idle": "2023-02-14T11:41:07.941539Z",
     "shell.execute_reply": "2023-02-14T11:41:07.940193Z",
     "shell.execute_reply.started": "2023-02-14T11:41:07.931032Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1345 Cowper St'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r'(\\d+)\\s+(\\w+)\\s+St')\n",
    "m = p.search('I live at 1345 Cowper St')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51b66854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:09.449528Z",
     "iopub.status.busy": "2023-02-14T11:41:09.448921Z",
     "iopub.status.idle": "2023-02-14T11:41:09.458379Z",
     "shell.execute_reply": "2023-02-14T11:41:09.457374Z",
     "shell.execute_reply.started": "2023-02-14T11:41:09.449475Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1345'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "607c0624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:11.023802Z",
     "iopub.status.busy": "2023-02-14T11:41:11.023153Z",
     "iopub.status.idle": "2023-02-14T11:41:11.032732Z",
     "shell.execute_reply": "2023-02-14T11:41:11.031688Z",
     "shell.execute_reply.started": "2023-02-14T11:41:11.023747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cowper'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a66e8b80",
   "metadata": {},
   "source": [
    "### Substitutions in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4da645fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:14.129209Z",
     "iopub.status.busy": "2023-02-14T11:41:14.128527Z",
     "iopub.status.idle": "2023-02-14T11:41:14.139507Z",
     "shell.execute_reply": "2023-02-14T11:41:14.138464Z",
     "shell.execute_reply.started": "2023-02-14T11:41:14.129154Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colour socks and colour shoes'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile('(blue|white|red)')\n",
    "p.sub('colour', 'blue socks and red shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f10b58",
   "metadata": {},
   "source": [
    "### Splitting on a regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0139153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:18.581500Z",
     "iopub.status.busy": "2023-02-14T11:41:18.580823Z",
     "iopub.status.idle": "2023-02-14T11:41:18.593441Z",
     "shell.execute_reply": "2023-02-14T11:41:18.592386Z",
     "shell.execute_reply.started": "2023-02-14T11:41:18.581445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'As',\n",
       " 'wet',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'said',\n",
       " 'Alice',\n",
       " 'in',\n",
       " 'a',\n",
       " 'melancholy',\n",
       " 'tone',\n",
       " 'it',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'dry',\n",
       " 'me',\n",
       " 'at',\n",
       " 'all',\n",
       " '']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A slightly better word tokenizer\n",
    "# The re split method returns you things that MATCH\n",
    "# the regular expression and skips stuff in between\n",
    "s = '''\\'As wet as ever,\\' said Alice\n",
    "    in a melancholy tone: \\'it doesn\\'t seem to\n",
    "    dry me at all.\\''''\n",
    "p = re.compile('\\W+')\n",
    "p.split(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a95461c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:21.690705Z",
     "iopub.status.busy": "2023-02-14T11:41:21.690087Z",
     "iopub.status.idle": "2023-02-14T11:41:21.700482Z",
     "shell.execute_reply": "2023-02-14T11:41:21.699470Z",
     "shell.execute_reply.started": "2023-02-14T11:41:21.690652Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'As',\n",
       " 'wet',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'said',\n",
       " 'Alice',\n",
       " 'in',\n",
       " 'a',\n",
       " 'melancholy',\n",
       " 'tone',\n",
       " 'it',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'dry',\n",
       " 'me',\n",
       " 'at',\n",
       " 'all',\n",
       " '']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again you can shortcut this.\n",
    "re.split('\\W+', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963176a2",
   "metadata": {},
   "source": [
    "Finally, I might note that there's even more complex and sometimes useful stuff you can do with regex that hasn't yet been covered. You can find all the glorious and messy details in the Python 3 library documentation: Case insensitivity, non-capturing groups, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d30d55",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "709ea922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:41:27.708615Z",
     "iopub.status.busy": "2023-02-14T11:41:27.707921Z",
     "iopub.status.idle": "2023-02-14T11:41:27.717859Z",
     "shell.execute_reply": "2023-02-14T11:41:27.716633Z",
     "shell.execute_reply.started": "2023-02-14T11:41:27.708560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = (\n",
    "    \"\"\"@Becky17 - i'm having a little trouble \"getting\"<br /> the whole twibes thing (but sometimes u gotta just get in there and try it).  :-)\"\"\",\n",
    "    \"\"\"Oh .. and follow @Spyker3292, @Domness, @Karlkempobrien, @Duidl_Media and @Chasetastic. Cheers for the Congrats! :D | #FollowSaturday\"\"\",\n",
    "    \"\"\"blade--trinity;;; sweeeeeeet. :)\"\"\",\n",
    "    \"\"\"@renay Thanks Renay! $9,000 yay =)\"\"\",\n",
    "    \"\"\"@denvy can try :) drop a tweet with \"##awaresg_tshirts\" so i can <strong>track</strong> orders #awaresg\"\"\",\n",
    "    \"\"\"U need to chk out & follow here, a more beautiful animal not anywhere else! @EmmaRileySutton :) #followfriday\"\"\",\n",
    "    \"\"\"@LadyB84 Manchester United??? Really??? Breaks my heart :-(http://www.twitpic.com/4x1fn\"\"\",\n",
    "    \"\"\"Can't wait till tomorrow =D\"\"\",\n",
    "    \"\"\"Big Shot's Funeral » Google » Peoria making its case for Google ... http://cli.gs/Wa8za#heading1.\"\"\",\n",
    "    \"\"\"Contact email@address.org today\"\"\",\n",
    "    \"\"\"@linguist278: Variations on phone numbers: +1 (800) 123-4567, (800) 123-4567. Not a real tweet!\"\"\",\n",
    "    \"\"\"RT @StanfordPraglab: Mole Day is coming up. Theme is Animole Kingdom: http://en.wikipedia.org/wiki/Mole_Day #Holidays :-)\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccbec4",
   "metadata": {},
   "source": [
    "Write a function that takes a list of strings, texts, and a regular expression, regex, as input and prints to standard output the subset that match regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f267d273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:53:28.100749Z",
     "iopub.status.busy": "2023-02-14T11:53:28.099857Z",
     "iopub.status.idle": "2023-02-14T11:53:28.109915Z",
     "shell.execute_reply": "2023-02-14T11:53:28.108542Z",
     "shell.execute_reply.started": "2023-02-14T11:53:28.100692Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Becky17 - i'm having a little trouble \"getting\"<br /> the whole twibes thing (but sometimes u gotta just get in there and try it).  :-)\n",
      "Oh .. and follow @Spyker3292, @Domness, @Karlkempobrien, @Duidl_Media and @Chasetastic. Cheers for the Congrats! :D | #FollowSaturday\n",
      "@renay Thanks Renay! $9,000 yay =)\n",
      "U need to chk out & follow here, a more beautiful animal not anywhere else! @EmmaRileySutton :) #followfriday\n",
      "@LadyB84 Manchester United??? Really??? Breaks my heart :-(http://www.twitpic.com/4x1fn\n",
      "Can't wait till tomorrow =D\n",
      "Big Shot's Funeral » Google » Peoria making its case for Google ... http://cli.gs/Wa8za#heading1.\n",
      "Contact email@address.org today\n",
      "@linguist278: Variations on phone numbers: +1 (800) 123-4567, (800) 123-4567. Not a real tweet!\n",
      "RT @StanfordPraglab: Mole Day is coming up. Theme is Animole Kingdom: http://en.wikipedia.org/wiki/Mole_Day #Holidays :-)\n"
     ]
    }
   ],
   "source": [
    "def matcher(texts, regex):\n",
    "    \"\"\"Takes a list of strings texts as input and prints to standard output the subset that match regex.\"\"\"\n",
    "    p = re.compile(regex)\n",
    "    \n",
    "    for i in texts:\n",
    "        if p.findall(i):\n",
    "            print(i)\n",
    "\n",
    "matcher(tweets, '[A-Z]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d319e41",
   "metadata": {},
   "source": [
    "Use this function to test out writing a few regular expressions, testing on the data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bef8aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:53:32.103566Z",
     "iopub.status.busy": "2023-02-14T11:53:32.102862Z",
     "iopub.status.idle": "2023-02-14T11:53:32.112285Z",
     "shell.execute_reply": "2023-02-14T11:53:32.110918Z",
     "shell.execute_reply.started": "2023-02-14T11:53:32.103510Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh .. and follow @Spyker3292, @Domness, @Karlkempobrien, @Duidl_Media and @Chasetastic. Cheers for the Congrats! :D | #FollowSaturday\n",
      "@denvy can try :) drop a tweet with \"##awaresg_tshirts\" so i can <strong>track</strong> orders #awaresg\n",
      "U need to chk out & follow here, a more beautiful animal not anywhere else! @EmmaRileySutton :) #followfriday\n",
      "Big Shot's Funeral » Google » Peoria making its case for Google ... http://cli.gs/Wa8za#heading1.\n",
      "RT @StanfordPraglab: Mole Day is coming up. Theme is Animole Kingdom: http://en.wikipedia.org/wiki/Mole_Day #Holidays :-)\n"
     ]
    }
   ],
   "source": [
    "def contains_hashtag(texts):\n",
    "    \"\"\"Uses matcher to find tweets that contain a hashtag. Assume a hashtag begins with # and has a non-null sequence of non-space characters after it.\"\"\"\n",
    "    matcher(texts, '(|.*W)#\\S+.*')\n",
    "\n",
    "contains_hashtag(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "360a9561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T11:56:58.246795Z",
     "iopub.status.busy": "2023-02-14T11:56:58.245888Z",
     "iopub.status.idle": "2023-02-14T11:56:58.255745Z",
     "shell.execute_reply": "2023-02-14T11:56:58.254662Z",
     "shell.execute_reply.started": "2023-02-14T11:56:58.246735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@renay Thanks Renay! $9,000 yay =)\n"
     ]
    }
   ],
   "source": [
    "def contains_money(texts):\n",
    "    \"\"\"Uses matcher to find tweets that contain a money amount. Assume a money amount begins with $ and has a non-null sequence of digits and periods after it.\"\"\"\n",
    "    matcher(texts, '.*\\$(\\d|\\.)+.*')\n",
    "    \n",
    "contains_money(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bba03b",
   "metadata": {},
   "source": [
    "Write a function that takes a list of strings, texts, and a regular expression, regex, as input and prints to standard output the substrings of each string that match regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0cf3598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T12:29:40.830260Z",
     "iopub.status.busy": "2023-02-14T12:29:40.829608Z",
     "iopub.status.idle": "2023-02-14T12:29:40.840246Z",
     "shell.execute_reply": "2023-02-14T12:29:40.839230Z",
     "shell.execute_reply.started": "2023-02-14T12:29:40.830205Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n",
      "['U']\n",
      "['C']\n",
      "['B']\n",
      "['C']\n",
      "['R']\n"
     ]
    }
   ],
   "source": [
    "def searcher(texts, regex):\n",
    "    \"\"\"Takes a list of strings texts as input and prints to standard output the substrings of each that match regex.\"\"\"\n",
    "    p = re.compile(regex)\n",
    "    \n",
    "    for i in texts:\n",
    "        m = p.findall(i)\n",
    "        if m:\n",
    "            #printing all the matches as lists:\n",
    "            print(m)\n",
    "            \n",
    "            #printing each match by itself:\n",
    "            #for j in m:\n",
    "                #print(j)\n",
    "\n",
    "searcher(tweets, '^[A-Z]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf6ae5",
   "metadata": {},
   "source": [
    "Use this function to test out writing a few regular expressions, testing on the data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcc8fea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T12:21:51.079922Z",
     "iopub.status.busy": "2023-02-14T12:21:51.079132Z",
     "iopub.status.idle": "2023-02-14T12:21:51.086775Z",
     "shell.execute_reply": "2023-02-14T12:21:51.085886Z",
     "shell.execute_reply.started": "2023-02-14T12:21:51.079873Z"
    }
   },
   "outputs": [],
   "source": [
    "def smileys(texts):\n",
    "    \"\"\"Uses searcher to find smiley faces, such as :) that appear in the list of strings, texts.\"\"\"\n",
    "    searcher(texts, '[:;=]-?[()pPD3]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8e5901a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T12:21:56.262711Z",
     "iopub.status.busy": "2023-02-14T12:21:56.261999Z",
     "iopub.status.idle": "2023-02-14T12:21:56.272175Z",
     "shell.execute_reply": "2023-02-14T12:21:56.270602Z",
     "shell.execute_reply.started": "2023-02-14T12:21:56.262653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-)\n",
      ":D\n",
      ":)\n",
      "=)\n",
      ":)\n",
      ":)\n",
      ":-(\n",
      "=D\n",
      ":-)\n"
     ]
    }
   ],
   "source": [
    "smileys(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e296fda7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T12:28:43.804894Z",
     "iopub.status.busy": "2023-02-14T12:28:43.804201Z",
     "iopub.status.idle": "2023-02-14T12:28:43.813270Z",
     "shell.execute_reply": "2023-02-14T12:28:43.811620Z",
     "shell.execute_reply.started": "2023-02-14T12:28:43.804830Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':)', ':D', ':-(']\n"
     ]
    }
   ],
   "source": [
    "example_text = [\"Yes. :) I'm really happy. :D Except when I'm sad. :-(\"]\n",
    "smileys(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813be0c0",
   "metadata": {},
   "source": [
    "Use the included file words-english.txt and search it \n",
    "for words that have a consonant cluster of 4 or more consonants at the end. We're just using a count of four orthographic consonants, not sounds (phonemes). We won't count y since it is usally a vowel at the end of words.\n",
    "\n",
    "Complete the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb091646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T12:38:54.482151Z",
     "iopub.status.busy": "2023-02-14T12:38:54.481506Z",
     "iopub.status.idle": "2023-02-14T12:38:54.491423Z",
     "shell.execute_reply": "2023-02-14T12:38:54.490477Z",
     "shell.execute_reply.started": "2023-02-14T12:38:54.482097Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_consonant_clusters(filename):\n",
    "    consonants = \"bcdfghjklmnpqrstvwxz\" # 'y' left out for added interest\n",
    "    \n",
    "    pattern = '[' + consonants + ']{4}$'\n",
    "    p = re.compile(pattern)\n",
    "    \n",
    "    answer = []\n",
    "    \n",
    "    file = open(filename)\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        \n",
    "        m = p.search(line)\n",
    "        \n",
    "        if m:\n",
    "            answer.append(line)\n",
    "            \n",
    "    file.close()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07796d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T12:39:01.481602Z",
     "iopub.status.busy": "2023-02-14T12:39:01.480794Z",
     "iopub.status.idle": "2023-02-14T12:39:01.536036Z",
     "shell.execute_reply": "2023-02-14T12:39:01.535319Z",
     "shell.execute_reply.started": "2023-02-14T12:39:01.481545Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amongst',\n",
       " 'angst',\n",
       " 'arclength',\n",
       " 'eighth',\n",
       " 'Ernst',\n",
       " 'Hirsch',\n",
       " 'length',\n",
       " 'Messrs',\n",
       " 'strength',\n",
       " 'thousandth',\n",
       " 'twelfth',\n",
       " 'unbeknownst',\n",
       " 'warmth',\n",
       " 'wavelength']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_consonant_clusters('words-english.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ef0ef",
   "metadata": {},
   "source": [
    "Use the included file gaddafi.txt and write a regular expression to match instances of his surname. You should match the first 112 but not the last 8!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "883042fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:01:05.414591Z",
     "iopub.status.busy": "2023-02-14T13:01:05.413776Z",
     "iopub.status.idle": "2023-02-14T13:01:05.426935Z",
     "shell.execute_reply": "2023-02-14T13:01:05.425599Z",
     "shell.execute_reply.started": "2023-02-14T13:01:05.414536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaddafi_matches(filename):\n",
    "    \n",
    "    first = \"(M(o|u|ou)(['`h]?[aA])?|O|Mau)mm?[ea]r\"\n",
    "    pre_last = \"([AEae][lI][- ])?\"\n",
    "    main_last = \"[KQG]h?(a|ua|e|u)([dt]h?(d|h|'|[td]h)? | zz)aff?[iy]\"\n",
    "    \n",
    "    last = pre_last + main_last\n",
    "    \n",
    "    forward = first + ' (\\w+ )*' + last + ' ( |$)'\n",
    "    backward = last + ', ' + first\n",
    "    \n",
    "    pattern = forward + '|' + backward\n",
    "    \n",
    "    p = re.compile(pattern)\n",
    "    \n",
    "    matches = 0\n",
    "    \n",
    "    file = open(filename)\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        \n",
    "        m = p.search(line)\n",
    "        \n",
    "        if m:\n",
    "            #print(line)\n",
    "            matches = matches + 1\n",
    "        else:\n",
    "            print(f\"This did not match: {line}\")\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbfd1447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T13:01:49.544902Z",
     "iopub.status.busy": "2023-02-14T13:01:49.544092Z",
     "iopub.status.idle": "2023-02-14T13:01:49.585386Z",
     "shell.execute_reply": "2023-02-14T13:01:49.584030Z",
     "shell.execute_reply.started": "2023-02-14T13:01:49.544847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This did not match: Qaddafi, Muammar\n",
      "This did not match: Al-Gathafi, Muammar\n",
      "This did not match: al-Qadhafi, Muammar\n",
      "This did not match: Al Qathafi, Mu'ammar\n",
      "This did not match: Al Qathafi, Muammar\n",
      "This did not match: El Gaddafi, Moamar\n",
      "This did not match: El Kadhafi, Moammar\n",
      "This did not match: El Kazzafi, Moamer\n",
      "This did not match: El Qathafi, Mu'Ammar\n",
      "This did not match: Gadafi, Muammar\n",
      "This did not match: Gaddafi, Moamar\n",
      "This did not match: Gadhafi, Mo'ammar\n",
      "This did not match: Gathafi, Muammar\n",
      "This did not match: Ghadafi, Muammar\n",
      "This did not match: Ghaddafi, Muammar\n",
      "This did not match: Ghaddafy, Muammar\n",
      "This did not match: Gheddafi, Muammar\n",
      "This did not match: Gheddafi, Muhammar\n",
      "This did not match: Kadaffi, Momar\n",
      "This did not match: Kad'afi, Mu`amar al- 20\n",
      "This did not match: Kaddafi, Muamar\n",
      "This did not match: Kaddafi, Muammar\n",
      "This did not match: Kadhafi, Moammar\n",
      "This did not match: Kadhafi, Mouammar\n",
      "This did not match: Kazzafi, Moammar\n",
      "This did not match: Khadafy, Moammar\n",
      "This did not match: Khaddafi, Muammar\n",
      "This did not match: Moamar al-Gaddafi\n",
      "This did not match: Moamar el Gaddafi\n",
      "This did not match: Moamar El Kadhafi\n",
      "This did not match: Moamar Gaddafi\n",
      "This did not match: Moamer El Kazzafi\n",
      "This did not match: Mo'ammar el-Gadhafi\n",
      "This did not match: Moammar El Kadhafi\n",
      "This did not match: Mo'ammar Gadhafi\n",
      "This did not match: Moammar Kadhafi\n",
      "This did not match: Moammar Khadafy\n",
      "This did not match: Moammar Qudhafi\n",
      "This did not match: Mu`amar al-Kad'afi\n",
      "This did not match: Mu'amar al-Kadafi\n",
      "This did not match: Muamar Al-Kaddafi\n",
      "This did not match: Muamar Kaddafi\n",
      "This did not match: Muamer Gadafi\n",
      "This did not match: Muammar Al-Gathafi\n",
      "This did not match: Muammar al-Khaddafi\n",
      "This did not match: Mu'ammar al-Qadafi\n",
      "This did not match: Mu'ammar al-Qaddafi\n",
      "This did not match: Muammar al-Qadhafi\n",
      "This did not match: Mu'ammar al-Qadhdhafi\n",
      "This did not match: Mu`ammar al-Qadhdhafi 50\n",
      "This did not match: Mu'ammar Al Qathafi\n",
      "This did not match: Muammar Al Qathafi\n",
      "This did not match: Muammar Gadafi\n",
      "This did not match: Muammar Gaddafi\n",
      "This did not match: Muammar Ghadafi\n",
      "This did not match: Muammar Ghaddafi\n",
      "This did not match: Muammar Ghaddafy\n",
      "This did not match: Muammar Gheddafi\n",
      "This did not match: Muammar Kaddafi\n",
      "This did not match: Muammar Khaddafi\n",
      "This did not match: Mu'ammar Qadafi\n",
      "This did not match: Muammar Qaddafi\n",
      "This did not match: Muammar Qadhafi\n",
      "This did not match: Mu'ammar Qadhdhafi\n",
      "This did not match: Muammar Quathafi\n",
      "This did not match: Mulazim Awwal Mu'ammar Muhammad Abu Minyar al-Qadhafi\n",
      "This did not match: Qadafi, Mu'ammar\n",
      "This did not match: Qadhafi, Muammar\n",
      "This did not match: Qadhdhafi, Mu`ammar\n",
      "This did not match: Qathafi, Mu'Ammar el 70\n",
      "This did not match: Quathafi, Muammar\n",
      "This did not match: Qudhafi, Moammar\n",
      "This did not match: Moamar AI Kadafi\n",
      "This did not match: Maummar Gaddafi\n",
      "This did not match: Moamar Gadhafi\n",
      "This did not match: Moamer Gaddafi\n",
      "This did not match: Moamer Kadhafi\n",
      "This did not match: Moamma Gaddafi\n",
      "This did not match: Moammar Gaddafi\n",
      "This did not match: Moammar Gadhafi\n",
      "This did not match: Moammar Ghadafi\n",
      "This did not match: Moammar Khadaffy\n",
      "This did not match: Moammar Khaddafi\n",
      "This did not match: Moammar el Gadhafi\n",
      "This did not match: Moammer Gaddafi\n",
      "This did not match: Mouammer al Gaddafi\n",
      "This did not match: Muamar Gaddafi\n",
      "This did not match: Muammar Al Ghaddafi\n",
      "This did not match: Muammar Al Qaddafi\n",
      "This did not match: Muammar Al Qaddafi\n",
      "This did not match: Muammar El Qaddafi\n",
      "This did not match: Muammar Gadaffi\n",
      "This did not match: Muammar Gadafy\n",
      "This did not match: Muammar Gaddhafi\n",
      "This did not match: Muammar Gadhafi\n",
      "This did not match: Muammar Ghadaffi\n",
      "This did not match: Muammar Qadthafi\n",
      "This did not match: Muammar al Gaddafi\n",
      "This did not match: Muammar el Gaddafy\n",
      "This did not match: Muammar el Gaddafi\n",
      "This did not match: Muammar el Qaddafi\n",
      "This did not match: Muammer Gadaffi\n",
      "This did not match: Muammer Gaddafi\n",
      "This did not match: Mummar Gaddafi\n",
      "This did not match: Omar Al Qathafi\n",
      "This did not match: Omar Mouammer Al Gaddafi\n",
      "This did not match: Omar Muammar Al Ghaddafi\n",
      "This did not match: Omar Muammar Al Qaddafi\n",
      "This did not match: Omar Muammar Al Qathafi\n",
      "This did not match: Omar Muammar Gaddafi\n",
      "This did not match: Omar Muammar Ghaddafi\n",
      "This did not match: Omar al Ghaddafi\n",
      "This did not match: # I think you shouldn't find these ones\n",
      "This did not match: Gagafy\n",
      "This did not match: Mummar Gadddafi\n",
      "This did not match: Quudafi, Muammar\n",
      "This did not match: Qudai, Muammar\n",
      "This did not match: Quhafi, Muammar\n",
      "This did not match: Mummar Gaddafiy\n",
      "This did not match: Mummar Gadaf\n",
      "This did not match: Omar Qaafi\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "total_num_m = gaddafi_matches('gaddafi.txt')\n",
    "print(total_num_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0c5d0-5761-47aa-b016-dd5de6f1d699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
